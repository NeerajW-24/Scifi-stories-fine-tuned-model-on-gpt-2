# -*- coding: utf-8 -*-
"""Fine-Tune GPT-2 on Custom Text.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eEFwiSGE4Mop5OOSNiw9tnp2qmR59u4L
"""

!pip install transformers datasets --quiet

from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, TextDataset, DataCollatorForLanguageModeling
import torch
import os

os.environ["WANDB_DISABLED"] = "true"

tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
model = GPT2LMHeadModel.from_pretrained("gpt2")

tokenizer.pad_token = tokenizer.eos_token
model.resize_token_embeddings(len(tokenizer))

def load_dataset(file_path, tokenizer, block_size=256):
    return TextDataset(
        tokenizer=tokenizer,
        file_path=file_path,
        block_size=block_size
    )

train_dataset = load_dataset("output.txt", tokenizer)

data_collator = DataCollatorForLanguageModeling(
    tokenizer=tokenizer, mlm=False
)

training_args = TrainingArguments(
    output_dir="./gpt2-finetuned",
    overwrite_output_dir=True,
    num_train_epochs=15,
    per_device_train_batch_size=2,
    save_steps=500,
    save_total_limit=2,
    logging_steps=40,
    prediction_loss_only=True
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    data_collator=data_collator,
)

print(len(train_dataset))

trainer.train()

trainer.save_model("./gpt2-finetuned")
tokenizer.save_pretrained("./gpt2-finetuned")



from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer

model = GPT2LMHeadModel.from_pretrained("./gpt2-finetuned")
tokenizer = GPT2Tokenizer.from_pretrained("./gpt2-finetuned")

generator = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer
)

import re
def postprocess_news_output(text):
    text = text.replace("“", '"').replace("”", '"').replace("’", "'").replace("‘", "'")

    text = re.sub(r"</?ref>", "", text)
    text = re.sub(r"\*+", "", text)

    text = re.sub(r"retailers\'s", "retailers'", text)

    text = re.sub(r"\s+", " ", text).strip()

    sentences = re.split(r'(?<=[.?!])\s+', text)
    if not sentences[-1][-1] in [".", "!", "?"]:
        sentences = sentences[:-1]

    return " ".join(sentences)

prompt="The man jumped on horizon...."

raw_output = generator(
    prompt,
    max_new_tokens=180,
    temperature=0.7,
    top_k=40,
    top_p=0.9,
    repetition_penalty=1.2,
    do_sample=True,
    pad_token_id=tokenizer.eos_token_id
    )[0]['generated_text']
cleaned_output = postprocess_news_output(raw_output)
print(cleaned_output)



